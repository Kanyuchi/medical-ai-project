{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drug Discovery - Molecular Property Prediction\n",
    "## Graph Neural Networks for Molecular Analysis\n",
    "\n",
    "This notebook uses Graph Neural Networks to predict molecular properties for drug discovery.\n",
    "\n",
    "**Estimated GPU Time:** 4-8 hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU\n",
    "import torch\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "import os\n",
    "project_dir = '/content/drive/MyDrive/medical-ai-project/drug-discovery'\n",
    "os.makedirs(project_dir, exist_ok=True)\n",
    "os.chdir(project_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies for molecular ML\n",
    "!pip install torch torchvision\n",
    "!pip install torch-geometric\n",
    "!pip install rdkit-pypi\n",
    "!pip install scikit-learn matplotlib seaborn\n",
    "!pip install pandas numpy\n",
    "!pip install deepchem  # Optional: for easy dataset loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "from torch_geometric.nn import GCNConv, GATConv, global_mean_pool, global_max_pool\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem, Descriptors\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Dataset Preparation\n",
    "\n",
    "Common molecular property datasets:\n",
    "- **QM9**: Quantum mechanical properties of small molecules\n",
    "- **ESOL**: Aqueous solubility prediction\n",
    "- **FreeSolv**: Hydration free energy\n",
    "- **Lipophilicity**: Octanol/water distribution coefficient\n",
    "- **BACE**: Binding affinity for Beta-secretase 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "BATCH_SIZE = 64\n",
    "NUM_EPOCHS = 100\n",
    "LEARNING_RATE = 0.001\n",
    "HIDDEN_DIM = 128\n",
    "NUM_LAYERS = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Molecular graph conversion\n",
    "def smiles_to_graph(smiles):\n",
    "    \"\"\"\n",
    "    Convert SMILES string to PyTorch Geometric graph\n",
    "    \n",
    "    Args:\n",
    "        smiles: SMILES string representation of molecule\n",
    "    \n",
    "    Returns:\n",
    "        PyG Data object\n",
    "    \"\"\"\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    if mol is None:\n",
    "        return None\n",
    "    \n",
    "    # Atom features\n",
    "    atom_features = []\n",
    "    for atom in mol.GetAtoms():\n",
    "        features = [\n",
    "            atom.GetAtomicNum(),\n",
    "            atom.GetDegree(),\n",
    "            atom.GetFormalCharge(),\n",
    "            atom.GetHybridization().real,\n",
    "            atom.GetIsAromatic(),\n",
    "            atom.GetTotalNumHs()\n",
    "        ]\n",
    "        atom_features.append(features)\n",
    "    \n",
    "    x = torch.tensor(atom_features, dtype=torch.float)\n",
    "    \n",
    "    # Edge indices (bonds)\n",
    "    edge_indices = []\n",
    "    for bond in mol.GetBonds():\n",
    "        i = bond.GetBeginAtomIdx()\n",
    "        j = bond.GetEndAtomIdx()\n",
    "        edge_indices.append([i, j])\n",
    "        edge_indices.append([j, i])  # Undirected graph\n",
    "    \n",
    "    edge_index = torch.tensor(edge_indices, dtype=torch.long).t().contiguous()\n",
    "    \n",
    "    return Data(x=x, edge_index=edge_index)\n",
    "\n",
    "\n",
    "def prepare_dataset(smiles_list, labels):\n",
    "    \"\"\"\n",
    "    Prepare dataset from SMILES strings and labels\n",
    "    \"\"\"\n",
    "    data_list = []\n",
    "    \n",
    "    for smiles, label in zip(smiles_list, labels):\n",
    "        graph = smiles_to_graph(smiles)\n",
    "        if graph is not None:\n",
    "            graph.y = torch.tensor([label], dtype=torch.float)\n",
    "            data_list.append(graph)\n",
    "    \n",
    "    return data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset (example using DeepChem)\n",
    "# import deepchem as dc\n",
    "# tasks, datasets, transformers = dc.molnet.load_esol(featurizer='ECFP')\n",
    "# train_dataset, val_dataset, test_dataset = datasets\n",
    "\n",
    "# OR load from CSV\n",
    "# df = pd.read_csv('./data/molecules.csv')\n",
    "# smiles_list = df['smiles'].tolist()\n",
    "# labels = df['target_property'].tolist()\n",
    "\n",
    "# data_list = prepare_dataset(smiles_list, labels)\n",
    "# train_data, val_data = train_test_split(data_list, test_size=0.2, random_state=42)\n",
    "\n",
    "# train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "# val_loader = DataLoader(val_data, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "print(\"Dataset preparation functions ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Graph Neural Network Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MolecularGNN(nn.Module):\n",
    "    \"\"\"\n",
    "    Graph Neural Network for molecular property prediction\n",
    "    Uses Graph Attention Networks (GAT) for better performance\n",
    "    \"\"\"\n",
    "    def __init__(self, num_node_features, hidden_dim=128, num_layers=3, dropout=0.2):\n",
    "        super(MolecularGNN, self).__init__()\n",
    "        \n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        # Graph convolution layers\n",
    "        self.convs = nn.ModuleList()\n",
    "        self.convs.append(GATConv(num_node_features, hidden_dim, heads=4, dropout=dropout))\n",
    "        \n",
    "        for _ in range(num_layers - 2):\n",
    "            self.convs.append(GATConv(hidden_dim * 4, hidden_dim, heads=4, dropout=dropout))\n",
    "        \n",
    "        self.convs.append(GATConv(hidden_dim * 4, hidden_dim, heads=1, dropout=dropout))\n",
    "        \n",
    "        # Batch normalization\n",
    "        self.batch_norms = nn.ModuleList([\n",
    "            nn.BatchNorm1d(hidden_dim * 4) for _ in range(num_layers - 1)\n",
    "        ])\n",
    "        self.batch_norms.append(nn.BatchNorm1d(hidden_dim))\n",
    "        \n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(hidden_dim * 2, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, 64)\n",
    "        self.fc3 = nn.Linear(64, 1)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self, data):\n",
    "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
    "        \n",
    "        # Graph convolutions\n",
    "        for i, conv in enumerate(self.convs):\n",
    "            x = conv(x, edge_index)\n",
    "            x = self.batch_norms[i](x)\n",
    "            x = F.relu(x)\n",
    "            x = self.dropout(x)\n",
    "        \n",
    "        # Global pooling\n",
    "        x_mean = global_mean_pool(x, batch)\n",
    "        x_max = global_max_pool(x, batch)\n",
    "        x = torch.cat([x_mean, x_max], dim=1)\n",
    "        \n",
    "        # Fully connected layers\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model\n",
    "NUM_NODE_FEATURES = 6  # Based on atom features we extract\n",
    "\n",
    "model = MolecularGNN(\n",
    "    num_node_features=NUM_NODE_FEATURES,\n",
    "    hidden_dim=HIDDEN_DIM,\n",
    "    num_layers=NUM_LAYERS,\n",
    "    dropout=0.2\n",
    ").to(device)\n",
    "\n",
    "print(f\"Model loaded on {device}\")\n",
    "print(f\"Total parameters: {sum(p.numel() for p in model.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Training Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss and optimizer\n",
    "criterion = nn.MSELoss()  # For regression tasks\n",
    "# Use nn.CrossEntropyLoss() for classification tasks\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=1e-5)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode='min', factor=0.5, patience=10, verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training functions\n",
    "def train_epoch(model, train_loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    for data in train_loader:\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model(data)\n",
    "        loss = criterion(output, data.y)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item() * data.num_graphs\n",
    "    \n",
    "    return total_loss / len(train_loader.dataset)\n",
    "\n",
    "\n",
    "def validate_epoch(model, val_loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    predictions = []\n",
    "    true_values = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data in val_loader:\n",
    "            data = data.to(device)\n",
    "            output = model(data)\n",
    "            loss = criterion(output, data.y)\n",
    "            \n",
    "            total_loss += loss.item() * data.num_graphs\n",
    "            predictions.extend(output.cpu().numpy())\n",
    "            true_values.extend(data.y.cpu().numpy())\n",
    "    \n",
    "    avg_loss = total_loss / len(val_loader.dataset)\n",
    "    predictions = np.array(predictions)\n",
    "    true_values = np.array(true_values)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    mae = mean_absolute_error(true_values, predictions)\n",
    "    rmse = np.sqrt(mean_squared_error(true_values, predictions))\n",
    "    r2 = r2_score(true_values, predictions)\n",
    "    \n",
    "    return avg_loss, mae, rmse, r2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = {\n",
    "    'train_loss': [],\n",
    "    'val_loss': [],\n",
    "    'val_mae': [],\n",
    "    'val_rmse': [],\n",
    "    'val_r2': []\n",
    "}\n",
    "\n",
    "best_loss = float('inf')\n",
    "\n",
    "# TODO: Uncomment when data is ready\n",
    "# for epoch in range(NUM_EPOCHS):\n",
    "#     print(f'\\nEpoch {epoch+1}/{NUM_EPOCHS}')\n",
    "#     print('-' * 50)\n",
    "    \n",
    "#     train_loss = train_epoch(model, train_loader, criterion, optimizer, device)\n",
    "#     val_loss, val_mae, val_rmse, val_r2 = validate_epoch(model, val_loader, criterion, device)\n",
    "    \n",
    "#     history['train_loss'].append(train_loss)\n",
    "#     history['val_loss'].append(val_loss)\n",
    "#     history['val_mae'].append(val_mae)\n",
    "#     history['val_rmse'].append(val_rmse)\n",
    "#     history['val_r2'].append(val_r2)\n",
    "    \n",
    "#     print(f'Train Loss: {train_loss:.4f}')\n",
    "#     print(f'Val Loss: {val_loss:.4f} | MAE: {val_mae:.4f} | RMSE: {val_rmse:.4f} | R²: {val_r2:.4f}')\n",
    "    \n",
    "#     scheduler.step(val_loss)\n",
    "    \n",
    "#     if val_loss < best_loss:\n",
    "#         best_loss = val_loss\n",
    "#         torch.save(model.state_dict(), './models/best_drug_discovery_model.pth')\n",
    "#         print(f'✓ Best model saved with loss: {best_loss:.4f}')\n",
    "\n",
    "print(\"Training setup complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Evaluation & Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "def plot_history(history):\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "    \n",
    "    # Loss\n",
    "    axes[0, 0].plot(history['train_loss'], label='Train Loss')\n",
    "    axes[0, 0].plot(history['val_loss'], label='Val Loss')\n",
    "    axes[0, 0].set_xlabel('Epoch')\n",
    "    axes[0, 0].set_ylabel('Loss')\n",
    "    axes[0, 0].set_title('Training and Validation Loss')\n",
    "    axes[0, 0].legend()\n",
    "    axes[0, 0].grid(True)\n",
    "    \n",
    "    # MAE\n",
    "    axes[0, 1].plot(history['val_mae'])\n",
    "    axes[0, 1].set_xlabel('Epoch')\n",
    "    axes[0, 1].set_ylabel('MAE')\n",
    "    axes[0, 1].set_title('Validation MAE')\n",
    "    axes[0, 1].grid(True)\n",
    "    \n",
    "    # RMSE\n",
    "    axes[1, 0].plot(history['val_rmse'])\n",
    "    axes[1, 0].set_xlabel('Epoch')\n",
    "    axes[1, 0].set_ylabel('RMSE')\n",
    "    axes[1, 0].set_title('Validation RMSE')\n",
    "    axes[1, 0].grid(True)\n",
    "    \n",
    "    # R²\n",
    "    axes[1, 1].plot(history['val_r2'])\n",
    "    axes[1, 1].set_xlabel('Epoch')\n",
    "    axes[1, 1].set_ylabel('R²')\n",
    "    axes[1, 1].set_title('Validation R² Score')\n",
    "    axes[1, 1].grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('./training_history.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "# plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction vs actual plot\n",
    "def plot_predictions(y_true, y_pred):\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.scatter(y_true, y_pred, alpha=0.5)\n",
    "    plt.plot([y_true.min(), y_true.max()], [y_true.min(), y_true.max()], 'r--', lw=2)\n",
    "    plt.xlabel('True Values')\n",
    "    plt.ylabel('Predictions')\n",
    "    plt.title('Predicted vs Actual Molecular Properties')\n",
    "    plt.grid(True)\n",
    "    plt.savefig('./predictions.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Molecular Visualization\n",
    "\n",
    "Visualize molecules and their predicted properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit.Chem import Draw\n",
    "\n",
    "def visualize_molecules(smiles_list, predictions, true_values, n_samples=6):\n",
    "    \"\"\"\n",
    "    Visualize molecules with their predicted and true property values\n",
    "    \"\"\"\n",
    "    mols = [Chem.MolFromSmiles(s) for s in smiles_list[:n_samples]]\n",
    "    legends = [\n",
    "        f'Pred: {pred:.2f}\\nTrue: {true:.2f}' \n",
    "        for pred, true in zip(predictions[:n_samples], true_values[:n_samples])\n",
    "    ]\n",
    "    \n",
    "    img = Draw.MolsToGridImage(mols, molsPerRow=3, subImgSize=(300, 300), legends=legends)\n",
    "    return img\n",
    "\n",
    "# Example usage:\n",
    "# img = visualize_molecules(test_smiles, predictions, true_values)\n",
    "# img.save('./molecule_predictions.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
